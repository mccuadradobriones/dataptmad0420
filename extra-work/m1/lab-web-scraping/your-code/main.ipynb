{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended content.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit the urls below and take a look at their source code through Chrome DevTools. You'll need to identify the html tags, special class names, etc used in the html content you are expected to extract.\n",
    "\n",
    "**Resources**:\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide)\n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are already imported for you. If you prefer to use additional libraries feel free to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from twitterscraper import query_tweets\n",
    "import datetime as dt\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "cool_people = soup.find_all('h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cool_people=re.findall('href.*\\w+.*\\s\\w*\\s.*', str(cool_people))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(jpsim) JP Simard', (frenck) Franck Nijhof', (borkdude) Michiel Borkent', (antfu) Anthony Fu', (fonsp) Fons van der Plas', (Koenkk) Koen Kanters', (balloob) Paulus Schoutsen', (asottile) Anthony Sottile', (punker76) Jan Karger ツ ☀', (jsuarezruiz) Javier Suárez', (sdushantha) Siddharth Dushantha', (tiangolo) Sebastián Ramírez', (ai) Andrey Sitnik', (MathewSachin) Mathew Sachin', (mattleibow) Matthew Leibowitz', (chrisbanes) Chris Banes', (mikepenz) Mike Penz', (PatilShreyas) Shreyas Patil', (stefanprodan) Stefan Prodan', (luke-jr) Luke Dashjr', (muukii) Hiroshi Kimura', (flybayer) Brandon Bayer', (seancdavis) Sean C Davis', (akaszynski) Alex Kaszynski', (isaacs) isaacs']\n"
     ]
    }
   ],
   "source": [
    "cool_people_1=re.sub(r'\">\\\\n',')',str(cool_people))   \n",
    "cool_people_2=re.sub('\\'href=\"/','(',str(cool_people_1))\n",
    "cool_people_3=re.sub('[\\s]{2,20}',' ',str(cool_people_2))\n",
    "print(cool_people_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub.\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' facebookresearch',\n",
       " ' guardicore',\n",
       " ' geohot',\n",
       " ' jofpin',\n",
       " ' LonamiWebs',\n",
       " ' django',\n",
       " ' python',\n",
       " ' lazyprogrammer',\n",
       " ' teja156',\n",
       " ' sherlock',\n",
       " ' Cog',\n",
       " ' iearn',\n",
       " ' PrefectHQ',\n",
       " ' tiangolo',\n",
       " ' pennersr',\n",
       " ' TheSpeedX',\n",
       " ' aapatre',\n",
       " ' plotly',\n",
       " ' microsoft',\n",
       " ' thenewboston',\n",
       " ' ageitgey',\n",
       " ' deepfakes',\n",
       " ' ct',\n",
       " ' jackfrued',\n",
       " ' iperov']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "cool_repos = soup.find_all('h1')\n",
    "cool_repos=re.findall('class=\"text-normal\">\\n.*', str(cool_repos))\n",
    "re.findall(r'(\\s\\b\\w*)',str(cool_repos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 29647.89it/s]\n"
     ]
    }
   ],
   "source": [
    "urls = []\n",
    "for img in tqdm(soup.find_all('img')):\n",
    "    img_url = img.attrs.get(\"src\")\n",
    "    urls.append(urljoin(url, img_url))\n",
    "    if not img_url:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/8/8c/Extended-protection-shackle.svg/20px-Extended-protection-shackle.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Newman_Laugh-O-Gram_%281921%29.webm/220px-seek%3D2-Newman_Laugh-O-Gram_%281921%29.webm.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/170px-Trolley_Troubles_poster.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg/170px-Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/170px-Steamboat-willie.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/170px-Walt_Disney_1935.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/220px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/170px-Disney_drawing_goofy.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/220px-DisneySchiphol1951.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/220px-WaltDisneyplansDisneylandDec1954.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/170px-Walt_disney_portrait_right.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/170px-Walt_Disney_Grave.JPG',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Roy_O._Disney_with_Company_at_Press_Conference.jpg/170px-Roy_O._Disney_with_Company_at_Press_Conference.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Disney_Display_Case.JPG/170px-Disney_Display_Case.JPG',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/170px-Disney1968.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/30px-Animation_disc.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/29px-P_vip.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/24px-Magic_Kingdom_castle.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/30px-Video-x-generic.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/30px-Flag_of_Los_Angeles_County%2C_California.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/30px-Blank_television_set.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/30px-Flag_of_the_United_States.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/22px-Commons-logo.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/25px-Wikiquote-logo.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Wikidata-logo.svg/30px-Wikidata-logo.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " 'https://en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1',\n",
       " 'https://en.wikipedia.org/static/images/footer/wikimedia-button.png',\n",
       " 'https://en.wikipedia.org/static/images/footer/poweredby_mediawiki_88x31.png']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:00<00:00, 58987.25it/s]\n"
     ]
    }
   ],
   "source": [
    "urls = []\n",
    "for link in tqdm(soup.find_all('a')):\n",
    "    link_url = link.attrs.get(\"href\")\n",
    "    urls.append(urljoin(url, link_url))\n",
    "    if not link_url:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Python',\n",
       " 'https://en.wikipedia.org/wiki/Python#mw-head',\n",
       " 'https://en.wikipedia.org/wiki/Python#searchInput',\n",
       " 'https://en.wiktionary.org/wiki/Python',\n",
       " 'https://en.wiktionary.org/wiki/python',\n",
       " 'https://en.wikipedia.org/wiki/Pythons',\n",
       " 'https://en.wikipedia.org/wiki/Python_(genus)',\n",
       " 'https://en.wikipedia.org/wiki/Python#Computing',\n",
       " 'https://en.wikipedia.org/wiki/Python#People',\n",
       " 'https://en.wikipedia.org/wiki/Python#Roller_coasters',\n",
       " 'https://en.wikipedia.org/wiki/Python#Vehicles',\n",
       " 'https://en.wikipedia.org/wiki/Python#Weaponry',\n",
       " 'https://en.wikipedia.org/wiki/Python#Other_uses',\n",
       " 'https://en.wikipedia.org/wiki/Python#See_also',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=1',\n",
       " 'https://en.wikipedia.org/wiki/Python_(programming_language)',\n",
       " 'https://en.wikipedia.org/wiki/CMU_Common_Lisp',\n",
       " 'https://en.wikipedia.org/wiki/PERQ#PERQ_3',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=2',\n",
       " 'https://en.wikipedia.org/wiki/Python_of_Aenus',\n",
       " 'https://en.wikipedia.org/wiki/Python_(painter)',\n",
       " 'https://en.wikipedia.org/wiki/Python_of_Byzantium',\n",
       " 'https://en.wikipedia.org/wiki/Python_of_Catana',\n",
       " 'https://en.wikipedia.org/wiki/Python_Anghelo',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=3',\n",
       " 'https://en.wikipedia.org/wiki/Python_(Efteling)',\n",
       " 'https://en.wikipedia.org/wiki/Python_(Busch_Gardens_Tampa_Bay)',\n",
       " 'https://en.wikipedia.org/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=4',\n",
       " 'https://en.wikipedia.org/wiki/Python_(automobile_maker)',\n",
       " 'https://en.wikipedia.org/wiki/Python_(Ford_prototype)',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=5',\n",
       " 'https://en.wikipedia.org/wiki/Python_(missile)',\n",
       " 'https://en.wikipedia.org/wiki/Python_(nuclear_primary)',\n",
       " 'https://en.wikipedia.org/wiki/Colt_Python',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=6',\n",
       " 'https://en.wikipedia.org/wiki/PYTHON',\n",
       " 'https://en.wikipedia.org/wiki/Python_(film)',\n",
       " 'https://en.wikipedia.org/wiki/Python_(mythology)',\n",
       " 'https://en.wikipedia.org/wiki/Monty_Python',\n",
       " 'https://en.wikipedia.org/wiki/Python_(Monty)_Pictures',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=7',\n",
       " 'https://en.wikipedia.org/wiki/Cython',\n",
       " 'https://en.wikipedia.org/wiki/Pyton',\n",
       " 'https://en.wikipedia.org/wiki/Pithon',\n",
       " 'https://en.wikipedia.org/wiki/File:Disambig_gray.svg',\n",
       " 'https://en.wikipedia.org/wiki/Help:Disambiguation',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&oldid=987482924',\n",
       " 'https://en.wikipedia.org/wiki/Help:Category',\n",
       " 'https://en.wikipedia.org/wiki/Category:Disambiguation_pages',\n",
       " 'https://en.wikipedia.org/wiki/Category:Human_name_disambiguation_pages',\n",
       " 'https://en.wikipedia.org/wiki/Category:Disambiguation_pages_with_given-name-holder_lists',\n",
       " 'https://en.wikipedia.org/wiki/Category:Disambiguation_pages_with_short_descriptions',\n",
       " 'https://en.wikipedia.org/wiki/Category:Short_description_is_different_from_Wikidata',\n",
       " 'https://en.wikipedia.org/wiki/Category:All_article_disambiguation_pages',\n",
       " 'https://en.wikipedia.org/wiki/Category:All_disambiguation_pages',\n",
       " 'https://en.wikipedia.org/wiki/Category:Animal_common_name_disambiguation_pages',\n",
       " 'https://en.wikipedia.org/wiki/Special:MyTalk',\n",
       " 'https://en.wikipedia.org/wiki/Special:MyContributions',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Python',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Python',\n",
       " 'https://en.wikipedia.org/wiki/Python',\n",
       " 'https://en.wikipedia.org/wiki/Talk:Python',\n",
       " 'https://en.wikipedia.org/wiki/Python',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&action=edit',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&action=history',\n",
       " 'https://en.wikipedia.org/wiki/Main_Page',\n",
       " 'https://en.wikipedia.org/wiki/Main_Page',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:Contents',\n",
       " 'https://en.wikipedia.org/wiki/Portal:Current_events',\n",
       " 'https://en.wikipedia.org/wiki/Special:Random',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:About',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:Contact_us',\n",
       " 'https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en',\n",
       " 'https://en.wikipedia.org/wiki/Help:Contents',\n",
       " 'https://en.wikipedia.org/wiki/Help:Introduction',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:Community_portal',\n",
       " 'https://en.wikipedia.org/wiki/Special:RecentChanges',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard',\n",
       " 'https://en.wikipedia.org/wiki/Special:WhatLinksHere/Python',\n",
       " 'https://en.wikipedia.org/wiki/Special:RecentChangesLinked/Python',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard',\n",
       " 'https://en.wikipedia.org/wiki/Special:SpecialPages',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&oldid=987482924',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&action=info',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Python&id=987482924&wpFormIdentifier=titleform',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Python&action=show-download-screen',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&printable=yes',\n",
       " 'https://commons.wikimedia.org/wiki/Category:Python',\n",
       " 'https://af.wikipedia.org/wiki/Python',\n",
       " 'https://als.wikipedia.org/wiki/Python',\n",
       " 'https://ar.wikipedia.org/wiki/%D8%A8%D8%A7%D9%8A%D8%AB%D9%88%D9%86_(%D8%AA%D9%88%D8%B6%D9%8A%D8%AD)',\n",
       " 'https://az.wikipedia.org/wiki/Python',\n",
       " 'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%BE%E0%A6%87%E0%A6%A5%E0%A6%A8_(%E0%A6%A6%E0%A7%8D%E0%A6%AC%E0%A7%8D%E0%A6%AF%E0%A6%B0%E0%A7%8D%E0%A6%A5%E0%A6%A4%E0%A6%BE_%E0%A6%A8%E0%A6%BF%E0%A6%B0%E0%A6%B8%E0%A6%A8)',\n",
       " 'https://be.wikipedia.org/wiki/Python',\n",
       " 'https://bg.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%BF%D0%BE%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)',\n",
       " 'https://cs.wikipedia.org/wiki/Python_(rozcestn%C3%ADk)',\n",
       " 'https://da.wikipedia.org/wiki/Python',\n",
       " 'https://de.wikipedia.org/wiki/Python',\n",
       " 'https://eo.wikipedia.org/wiki/Pitono_(apartigilo)',\n",
       " 'https://eu.wikipedia.org/wiki/Python_(argipena)',\n",
       " 'https://fa.wikipedia.org/wiki/%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86',\n",
       " 'https://fr.wikipedia.org/wiki/Python',\n",
       " 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%84%A0',\n",
       " 'https://hr.wikipedia.org/wiki/Python_(razdvojba)',\n",
       " 'https://io.wikipedia.org/wiki/Pitono',\n",
       " 'https://id.wikipedia.org/wiki/Python',\n",
       " 'https://ia.wikipedia.org/wiki/Python_(disambiguation)',\n",
       " 'https://is.wikipedia.org/wiki/Python_(a%C3%B0greining)',\n",
       " 'https://it.wikipedia.org/wiki/Python_(disambigua)',\n",
       " 'https://he.wikipedia.org/wiki/%D7%A4%D7%99%D7%AA%D7%95%D7%9F',\n",
       " 'https://ka.wikipedia.org/wiki/%E1%83%9E%E1%83%98%E1%83%97%E1%83%9D%E1%83%9C%E1%83%98_(%E1%83%9B%E1%83%A0%E1%83%90%E1%83%95%E1%83%90%E1%83%9A%E1%83%9B%E1%83%9C%E1%83%98%E1%83%A8%E1%83%95%E1%83%9C%E1%83%94%E1%83%9A%E1%83%9D%E1%83%95%E1%83%90%E1%83%9C%E1%83%98)',\n",
       " 'https://kg.wikipedia.org/wiki/Mboma_(nyoka)',\n",
       " 'https://la.wikipedia.org/wiki/Python_(discretiva)',\n",
       " 'https://lb.wikipedia.org/wiki/Python',\n",
       " 'https://hu.wikipedia.org/wiki/Python_(egy%C3%A9rtelm%C5%B1s%C3%ADt%C5%91_lap)',\n",
       " 'https://mr.wikipedia.org/wiki/%E0%A4%AA%E0%A4%BE%E0%A4%AF%E0%A4%A5%E0%A5%89%E0%A4%A8_(%E0%A4%86%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%B5%E0%A4%B2%E0%A5%80_%E0%A4%AD%E0%A4%BE%E0%A4%B7%E0%A4%BE)',\n",
       " 'https://nl.wikipedia.org/wiki/Python',\n",
       " 'https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%82%BD%E3%83%B3',\n",
       " 'https://no.wikipedia.org/wiki/Pyton',\n",
       " 'https://pl.wikipedia.org/wiki/Pyton',\n",
       " 'https://pt.wikipedia.org/wiki/Python_(desambigua%C3%A7%C3%A3o)',\n",
       " 'https://ru.wikipedia.org/wiki/Python_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)',\n",
       " 'https://sk.wikipedia.org/wiki/Python',\n",
       " 'https://sr.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%B2%D0%B8%D1%88%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%BD%D0%B0_%D0%BE%D0%B4%D1%80%D0%B5%D0%B4%D0%BD%D0%B8%D1%86%D0%B0)',\n",
       " 'https://sh.wikipedia.org/wiki/Python',\n",
       " 'https://fi.wikipedia.org/wiki/Python',\n",
       " 'https://sv.wikipedia.org/wiki/Pyton',\n",
       " 'https://th.wikipedia.org/wiki/%E0%B9%84%E0%B8%9E%E0%B8%97%E0%B8%AD%E0%B8%99',\n",
       " 'https://tr.wikipedia.org/wiki/Python',\n",
       " 'https://uk.wikipedia.org/wiki/%D0%9F%D1%96%D1%84%D0%BE%D0%BD',\n",
       " 'https://ur.wikipedia.org/wiki/%D9%BE%D8%A7%D8%A6%DB%8C%D8%AA%DA%BE%D9%88%D9%86',\n",
       " 'https://vi.wikipedia.org/wiki/Python',\n",
       " 'https://zh.wikipedia.org/wiki/Python_(%E6%B6%88%E6%AD%A7%E4%B9%89)',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452#sitelinks-wikipedia',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License',\n",
       " 'https://creativecommons.org/licenses/by-sa/3.0/',\n",
       " 'https://foundation.wikimedia.org/wiki/Terms_of_Use',\n",
       " 'https://foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " 'https://www.wikimediafoundation.org/',\n",
       " 'https://foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:About',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:General_disclaimer',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:Contact_us',\n",
       " 'https://en.m.wikipedia.org/w/index.php?title=Python&mobileaction=toggle_view_mobile',\n",
       " 'https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute',\n",
       " 'https://stats.wikimedia.org/#/en.wikipedia.org',\n",
       " 'https://foundation.wikimedia.org/wiki/Cookie_statement',\n",
       " 'https://wikimediafoundation.org/',\n",
       " 'https://www.mediawiki.org/']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the number of titles that have changed in the United States Code since its last release point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 306/306 [00:00<00:00, 285911.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "urls = []\n",
    "for title in tqdm(soup.find_all(\"div\")):\n",
    "    title_name = title.attrs.get(\"class\")\n",
    "    if title_name==['usctitlechanged']:\n",
    "        title=re.sub('(\\<.*?\\>)',\"\",str(title))\n",
    "        title=re.sub('\\\\n',\"\",str(title))\n",
    "        title=title.strip()\n",
    "        urls.append(title)\n",
    "    if not title_name:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 8 - Aliens and Nationality\n",
      "Title 11 - Bankruptcy ٭\n",
      "Title 15 - Commerce and Trade\n",
      "Title 18 - Crimes and Criminal Procedure ٭\n",
      "Title 25 - Indians\n",
      "Title 31 - Money and Finance ٭\n",
      "Title 32 - National Guard ٭\n",
      "Title 38 - Veterans' Benefits ٭\n",
      "Title 42 - The Public Health and Welfare\n",
      "Title 47 - Telecommunications\n",
      "Title 51 - National and Commercial Space Programs ٭\n"
     ]
    }
   ],
   "source": [
    "for i in urls:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find a Python list with the top ten FBI's Most Wanted names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 37237.57it/s]\n"
     ]
    }
   ],
   "source": [
    "urls = []\n",
    "for img in tqdm(soup.find_all('img')):\n",
    "    img_url = img.attrs.get(\"alt\")\n",
    "    urls.append(img_url)\n",
    "    if not img_url:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARNOLDO JIMENEZ',\n",
       " 'JASON DEREK BROWN',\n",
       " 'ALEXIS FLORES',\n",
       " 'JOSE RODOLFO VILLARREAL-HERNANDEZ',\n",
       " 'EUGENE PALMER',\n",
       " 'RAFAEL CARO-QUINTERO',\n",
       " 'ROBERT WILLIAM FISHER',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'ALEJANDRO ROSALES CASTILLO',\n",
       " 'YASER ABDEL SAID']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "datetime=soup.find_all(\"td\", class_=\"tabev6\")\n",
    "latlon=soup.find_all(\"td\", class_=\"tabev1\")\n",
    "ll=soup.find_all(\"td\", class_=\"tabev2\")\n",
    "region=soup.find_all(\"td\", class_=\"tb_region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon=[re.sub('<td class=\"tabev1\">','',str(i)) for i in latlon]\n",
    "latlon=[re.sub('</td>','',str(i)) for i in latlon]\n",
    "latlon=[re.sub('\\xa0','',str(i)) for i in latlon]\n",
    "latlon =[latlon[i:i + 2] for i in range(0, len(latlon), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll=[re.sub('<td class=\"tabev2\">','',str(i)) for i in ll]\n",
    "ll=[re.sub('</td>','',str(i)) for i in ll]\n",
    "ll=[re.sub('[\\d]+','',str(i)) for i in ll]\n",
    "ll=[re.sub('\\.','',str(i)) for i in ll]\n",
    "ll=[i[:-2] for i in ll if i]\n",
    "ll =[ll[i:i + 2] for i in range(0, len(ll), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitud=[]\n",
    "longitud=[]\n",
    "for i,y in zip(latlon,ll):\n",
    "    latitud.append(i[0]+' '+y[0])\n",
    "    longitud.append(i[1]+' '+y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime=[re.findall('20[\\d+].*</a>',str(i)) for i in datetime]\n",
    "datetime=[re.sub('</a>','',str(i)) for i in datetime]\n",
    "datetime=[i[2:-2] for i in datetime]\n",
    "datetime=[re.sub('\\\\\\.*a0',' ',str(i)) for i in datetime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "region=[re.sub('<td class=\"tb_region\" id=\"reg.*?>','',str(i)) for i in region]\n",
    "region=[re.sub('</td>','',str(i)) for i in region]\n",
    "region=[i[1:] for i in region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes=pd.DataFrame(data={'Date':datetime,'Longitud':longitud,'Latitud':latitud,'Region':region})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Longitud</th>\n",
       "      <th>Latitud</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>16:22:22.5</td>\n",
       "      <td>26.84 E</td>\n",
       "      <td>37.87 N</td>\n",
       "      <td>DODECANESE ISLANDS, GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>16:16:49.2</td>\n",
       "      <td>66.86 W</td>\n",
       "      <td>17.87 N</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>16:06:19.2</td>\n",
       "      <td>26.99 E</td>\n",
       "      <td>37.83 N</td>\n",
       "      <td>DODECANESE ISLANDS, GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>16:05:13.4</td>\n",
       "      <td>9.15 E</td>\n",
       "      <td>46.90 N</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>16:03:20.0</td>\n",
       "      <td>111.34 E</td>\n",
       "      <td>8.80 S</td>\n",
       "      <td>JAVA, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>16:02:49.1</td>\n",
       "      <td>20.65 E</td>\n",
       "      <td>38.18 N</td>\n",
       "      <td>GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>16:02:05.2</td>\n",
       "      <td>66.88 W</td>\n",
       "      <td>17.90 N</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>15:49:45.9</td>\n",
       "      <td>27.20 E</td>\n",
       "      <td>37.98 N</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>15:34:23.5</td>\n",
       "      <td>8.34 E</td>\n",
       "      <td>46.67 N</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>15:22:12.6</td>\n",
       "      <td>155.41 W</td>\n",
       "      <td>19.21 N</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>15:13:46.1</td>\n",
       "      <td>20.65 E</td>\n",
       "      <td>38.16 N</td>\n",
       "      <td>GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>15:00:45.8</td>\n",
       "      <td>26.84 E</td>\n",
       "      <td>37.82 N</td>\n",
       "      <td>DODECANESE ISLANDS, GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>14:59:30.0</td>\n",
       "      <td>83.83 W</td>\n",
       "      <td>9.47 N</td>\n",
       "      <td>COSTA RICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>14:41:16.8</td>\n",
       "      <td>53.43 E</td>\n",
       "      <td>27.41 N</td>\n",
       "      <td>SOUTHERN IRAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>14:40:16.0</td>\n",
       "      <td>27.14 E</td>\n",
       "      <td>37.85 N</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>14:38:02.6</td>\n",
       "      <td>122.91 W</td>\n",
       "      <td>39.37 N</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>14:34:56.2</td>\n",
       "      <td>27.00 E</td>\n",
       "      <td>37.85 N</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>14:16:27.0</td>\n",
       "      <td>69.57 W</td>\n",
       "      <td>22.34 S</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>14:14:39.8</td>\n",
       "      <td>66.87 W</td>\n",
       "      <td>17.85 N</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>14:13:32.0</td>\n",
       "      <td>94.59 W</td>\n",
       "      <td>16.93 N</td>\n",
       "      <td>OAXACA, MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>14:12:49.1</td>\n",
       "      <td>27.04 E</td>\n",
       "      <td>37.88 N</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>14:12:01.1</td>\n",
       "      <td>2.03 E</td>\n",
       "      <td>42.73 N</td>\n",
       "      <td>PYRENEES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>14:10:06.7</td>\n",
       "      <td>70.94 W</td>\n",
       "      <td>41.51 N</td>\n",
       "      <td>SOUTHERN NEW ENGLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>14:06:44.3</td>\n",
       "      <td>66.87 W</td>\n",
       "      <td>17.88 N</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>14:03:35.0</td>\n",
       "      <td>123.50 E</td>\n",
       "      <td>9.93 N</td>\n",
       "      <td>NEGROS- CEBU REG, PHILIPPINES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>13:54:50.2</td>\n",
       "      <td>66.86 W</td>\n",
       "      <td>17.88 N</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>13:46:35.0</td>\n",
       "      <td>123.39 E</td>\n",
       "      <td>0.15 S</td>\n",
       "      <td>SULAWESI, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>13:45:29.1</td>\n",
       "      <td>66.87 W</td>\n",
       "      <td>17.93 N</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>13:42:48.5</td>\n",
       "      <td>108.89 W</td>\n",
       "      <td>38.30 N</td>\n",
       "      <td>COLORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>13:42:24.0</td>\n",
       "      <td>126.35 E</td>\n",
       "      <td>1.36 N</td>\n",
       "      <td>MOLUCCA SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>13:32:34.5</td>\n",
       "      <td>108.91 W</td>\n",
       "      <td>38.29 N</td>\n",
       "      <td>COLORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>13:29:22.1</td>\n",
       "      <td>142.76 E</td>\n",
       "      <td>52.93 N</td>\n",
       "      <td>SAKHALIN, RUSSIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>13:27:19.9</td>\n",
       "      <td>27.05 E</td>\n",
       "      <td>37.75 N</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>13:26:25.2</td>\n",
       "      <td>75.76 E</td>\n",
       "      <td>33.51 N</td>\n",
       "      <td>EASTERN KASHMIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>13:14:07.0</td>\n",
       "      <td>121.56 E</td>\n",
       "      <td>6.14 S</td>\n",
       "      <td>FLORES SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>13:01:19.0</td>\n",
       "      <td>93.73 W</td>\n",
       "      <td>14.65 N</td>\n",
       "      <td>OFF COAST OF CHIAPAS, MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>12:39:09.4</td>\n",
       "      <td>26.75 E</td>\n",
       "      <td>37.54 N</td>\n",
       "      <td>DODECANESE ISLANDS, GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>12:32:23.0</td>\n",
       "      <td>128.81 E</td>\n",
       "      <td>2.55 S</td>\n",
       "      <td>CERAM SEA, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>12:29:08.6</td>\n",
       "      <td>68.13 W</td>\n",
       "      <td>19.27 N</td>\n",
       "      <td>DOMINICAN REPUBLIC REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>12:19:02.4</td>\n",
       "      <td>72.00 E</td>\n",
       "      <td>37.36 N</td>\n",
       "      <td>TAJIKISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>12:11:56.5</td>\n",
       "      <td>23.77 E</td>\n",
       "      <td>39.51 N</td>\n",
       "      <td>AEGEAN SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>12:10:50.0</td>\n",
       "      <td>23.70 E</td>\n",
       "      <td>39.53 N</td>\n",
       "      <td>AEGEAN SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>12:08:08.6</td>\n",
       "      <td>42.32 E</td>\n",
       "      <td>46.66 S</td>\n",
       "      <td>PRINCE EDWARD ISLANDS REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>12:06:19.0</td>\n",
       "      <td>66.79 W</td>\n",
       "      <td>24.00 S</td>\n",
       "      <td>JUJUY, ARGENTINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>11:57:06.0</td>\n",
       "      <td>126.56 E</td>\n",
       "      <td>3.95 N</td>\n",
       "      <td>KEPULAUAN TALAUD, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>11:52:37.8</td>\n",
       "      <td>117.99 W</td>\n",
       "      <td>38.16 N</td>\n",
       "      <td>NEVADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>11:46:19.9</td>\n",
       "      <td>26.55 E</td>\n",
       "      <td>45.63 N</td>\n",
       "      <td>ROMANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>11:32:10.4</td>\n",
       "      <td>7.77 E</td>\n",
       "      <td>48.64 N</td>\n",
       "      <td>FRANCE-GERMANY BORDER REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>11:31:19.0</td>\n",
       "      <td>101.22 W</td>\n",
       "      <td>17.54 N</td>\n",
       "      <td>GUERRERO, MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>11:29:51.3</td>\n",
       "      <td>26.51 E</td>\n",
       "      <td>37.91 N</td>\n",
       "      <td>DODECANESE ISLANDS, GREECE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Time  Longitud  Latitud                         Region\n",
       "0   2020-11-08  16:22:22.5   26.84 E  37.87 N     DODECANESE ISLANDS, GREECE\n",
       "1   2020-11-08  16:16:49.2   66.86 W  17.87 N             PUERTO RICO REGION\n",
       "2   2020-11-08  16:06:19.2   26.99 E  37.83 N     DODECANESE ISLANDS, GREECE\n",
       "3   2020-11-08  16:05:13.4    9.15 E  46.90 N                    SWITZERLAND\n",
       "4   2020-11-08  16:03:20.0  111.34 E   8.80 S                JAVA, INDONESIA\n",
       "5   2020-11-08  16:02:49.1   20.65 E  38.18 N                         GREECE\n",
       "6   2020-11-08  16:02:05.2   66.88 W  17.90 N             PUERTO RICO REGION\n",
       "7   2020-11-08  15:49:45.9   27.20 E  37.98 N                 WESTERN TURKEY\n",
       "8   2020-11-08  15:34:23.5    8.34 E  46.67 N                    SWITZERLAND\n",
       "9   2020-11-08  15:22:12.6  155.41 W  19.21 N       ISLAND OF HAWAII, HAWAII\n",
       "10  2020-11-08  15:13:46.1   20.65 E  38.16 N                         GREECE\n",
       "11  2020-11-08  15:00:45.8   26.84 E  37.82 N     DODECANESE ISLANDS, GREECE\n",
       "12  2020-11-08  14:59:30.0   83.83 W   9.47 N                     COSTA RICA\n",
       "13  2020-11-08  14:41:16.8   53.43 E  27.41 N                  SOUTHERN IRAN\n",
       "14  2020-11-08  14:40:16.0   27.14 E  37.85 N                 WESTERN TURKEY\n",
       "15  2020-11-08  14:38:02.6  122.91 W  39.37 N            NORTHERN CALIFORNIA\n",
       "16  2020-11-08  14:34:56.2   27.00 E  37.85 N                 WESTERN TURKEY\n",
       "17  2020-11-08  14:16:27.0   69.57 W  22.34 S             ANTOFAGASTA, CHILE\n",
       "18  2020-11-08  14:14:39.8   66.87 W  17.85 N             PUERTO RICO REGION\n",
       "19  2020-11-08  14:13:32.0   94.59 W  16.93 N                 OAXACA, MEXICO\n",
       "20  2020-11-08  14:12:49.1   27.04 E  37.88 N                 WESTERN TURKEY\n",
       "21  2020-11-08  14:12:01.1    2.03 E  42.73 N                       PYRENEES\n",
       "22  2020-11-08  14:10:06.7   70.94 W  41.51 N           SOUTHERN NEW ENGLAND\n",
       "23  2020-11-08  14:06:44.3   66.87 W  17.88 N             PUERTO RICO REGION\n",
       "24  2020-11-08  14:03:35.0  123.50 E   9.93 N  NEGROS- CEBU REG, PHILIPPINES\n",
       "25  2020-11-08  13:54:50.2   66.86 W  17.88 N             PUERTO RICO REGION\n",
       "26  2020-11-08  13:46:35.0  123.39 E   0.15 S            SULAWESI, INDONESIA\n",
       "27  2020-11-08  13:45:29.1   66.87 W  17.93 N             PUERTO RICO REGION\n",
       "28  2020-11-08  13:42:48.5  108.89 W  38.30 N                       COLORADO\n",
       "29  2020-11-08  13:42:24.0  126.35 E   1.36 N                    MOLUCCA SEA\n",
       "30  2020-11-08  13:32:34.5  108.91 W  38.29 N                       COLORADO\n",
       "31  2020-11-08  13:29:22.1  142.76 E  52.93 N               SAKHALIN, RUSSIA\n",
       "32  2020-11-08  13:27:19.9   27.05 E  37.75 N                 WESTERN TURKEY\n",
       "33  2020-11-08  13:26:25.2   75.76 E  33.51 N                EASTERN KASHMIR\n",
       "34  2020-11-08  13:14:07.0  121.56 E   6.14 S                     FLORES SEA\n",
       "35  2020-11-08  13:01:19.0   93.73 W  14.65 N   OFF COAST OF CHIAPAS, MEXICO\n",
       "36  2020-11-08  12:39:09.4   26.75 E  37.54 N     DODECANESE ISLANDS, GREECE\n",
       "37  2020-11-08  12:32:23.0  128.81 E   2.55 S           CERAM SEA, INDONESIA\n",
       "38  2020-11-08  12:29:08.6   68.13 W  19.27 N      DOMINICAN REPUBLIC REGION\n",
       "39  2020-11-08  12:19:02.4   72.00 E  37.36 N                     TAJIKISTAN\n",
       "40  2020-11-08  12:11:56.5   23.77 E  39.51 N                     AEGEAN SEA\n",
       "41  2020-11-08  12:10:50.0   23.70 E  39.53 N                     AEGEAN SEA\n",
       "42  2020-11-08  12:08:08.6   42.32 E  46.66 S   PRINCE EDWARD ISLANDS REGION\n",
       "43  2020-11-08  12:06:19.0   66.79 W  24.00 S               JUJUY, ARGENTINA\n",
       "44  2020-11-08  11:57:06.0  126.56 E   3.95 N    KEPULAUAN TALAUD, INDONESIA\n",
       "45  2020-11-08  11:52:37.8  117.99 W  38.16 N                         NEVADA\n",
       "46  2020-11-08  11:46:19.9   26.55 E  45.63 N                        ROMANIA\n",
       "47  2020-11-08  11:32:10.4    7.77 E  48.64 N   FRANCE-GERMANY BORDER REGION\n",
       "48  2020-11-08  11:31:19.0  101.22 W  17.54 N               GUERRERO, MEXICO\n",
       "49  2020-11-08  11:29:51.3   26.51 E  37.91 N     DODECANESE ISLANDS, GREECE"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes[['Date','Time']]=earthquakes['Date'].str.split(' ',expand = True)\n",
    "earthquakes=earthquakes[['Date', 'Time','Longitud', 'Latitud', 'Region']]\n",
    "earthquakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count the number of tweets by a given Twitter account.\n",
    "Ask the user for the handle (@handle) of a twitter account. You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = requests.get('https://twitter.com/VogueSpain').content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "tweet=soup.find_all(\"span\", class_=\"css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0\")\n",
    "tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account\n",
    "Ask the user for the handle (@handle) of a twitter account. You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://twitter.com/VogueSpain/followers'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "twitter=soup.find_all(\"span\", class_=\"css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "wiki=soup.find_all(\"a\", class_=\"link-box\")\n",
    "language_names=[re.findall('<strong>.*</strong>',str(i)) for i in wiki]\n",
    "numer_related_articles=[re.findall('ltr\">.*</bdi>',str(i)) for i in wiki]\n",
    "wikipedia=pd.DataFrame(data={'Language Names':language_names,'Number of Related Articles':numer_related_articles})\n",
    "wikipedia['Language Names']=wikipedia['Language Names'].apply(lambda x: re.sub('<strong>','',str(x)))\n",
    "wikipedia['Language Names']=wikipedia['Language Names'].apply(lambda x: re.sub('</strong>','',str(x)))\n",
    "wikipedia['Language Names']=wikipedia['Language Names'].apply(lambda x: x[2:-2])\n",
    "wikipedia['Number of Related Articles']=wikipedia['Number of Related Articles'].apply(lambda x: re.sub('[\\D+]','',str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language Names</th>\n",
       "      <th>Number of Related Articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>601830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Español</td>\n",
       "      <td>106370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>日本語</td>\n",
       "      <td>102350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deutsch</td>\n",
       "      <td>204950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Русский</td>\n",
       "      <td>106720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Français</td>\n",
       "      <td>202620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Italiano</td>\n",
       "      <td>106450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中文</td>\n",
       "      <td>101550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Português</td>\n",
       "      <td>100450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Polski</td>\n",
       "      <td>104350000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language Names Number of Related Articles\n",
       "0        English                  601830000\n",
       "1        Español                  106370000\n",
       "2            日本語                  102350000\n",
       "3        Deutsch                  204950000\n",
       "4        Русский                  106720000\n",
       "5       Français                  202620000\n",
       "6       Italiano                  106450000\n",
       "7             中文                  101550000\n",
       "8      Português                  100450000\n",
       "9         Polski                  104350000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Available Datasets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business and economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crime and justice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Defence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Government spending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Towns and cities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Transport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Available Datasets\n",
       "0   Business and economy\n",
       "1      Crime and justice\n",
       "2                Defence\n",
       "3              Education\n",
       "4            Environment\n",
       "5             Government\n",
       "6    Government spending\n",
       "7                 Health\n",
       "8                Mapping\n",
       "9                Society\n",
       "10      Towns and cities\n",
       "11             Transport"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "govuk=soup.find_all(\"a\", class_=\"govuk-link\")\n",
    "gov=[re.findall('>.*</a',str(i)) for i in govuk]\n",
    "gov=[re.sub('>','',str(i)) for i in gov]\n",
    "gov=[re.sub('</a','',str(i)) for i in gov]\n",
    "gov=[i[2:-2] for i in gov[3:]]\n",
    "gov=pd.DataFrame(data={'Available Datasets':gov})\n",
    "gov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the top 10 languages by number of native speakers stored in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "languages=soup.find_all(\"td\")\n",
    "languages=[re.sub('<td>','',str(i)) for i in languages]\n",
    "languages=[re.sub('\\n</td>','',str(i)) for i in languages]\n",
    "languages=[re.sub('<a href=\"/wiki/.*title=','',str(i)) for i in languages]\n",
    "languages=[re.sub('</a>','',str(i)) for i in languages]\n",
    "ll =[languages[i:i + 6] for i in range(0, len(languages), 6)]\n",
    "columns=['Rank','Language','Speakers','% of World pop.','Language family','Branch']\n",
    "languages=pd.DataFrame(data=ll,columns=columns)\n",
    "languages['Language']=languages['Language'].apply(lambda x:re.findall('>.*',str(x)))\n",
    "languages['Language']=languages['Language'].apply(lambda x:re.sub('>','',str(x)))\n",
    "languages['Language']=languages['Language'].apply(lambda x:re.sub('<.*','',str(x)))\n",
    "languages['Language']=languages['Language'].apply(lambda x:x[2:-2])\n",
    "languages.drop(columns=['Language family','Branch'],inplace=True)\n",
    "\n",
    "languages=languages.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Speakers</th>\n",
       "      <th>% of World pop.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>918</td>\n",
       "      <td>11.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>480</td>\n",
       "      <td>5.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>379</td>\n",
       "      <td>4.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hindustan</td>\n",
       "      <td>341</td>\n",
       "      <td>4.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>228</td>\n",
       "      <td>2.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>221</td>\n",
       "      <td>2.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Russian</td>\n",
       "      <td>154</td>\n",
       "      <td>2.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>128</td>\n",
       "      <td>1.66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Western Punja</td>\n",
       "      <td>92.7</td>\n",
       "      <td>1.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Marathi</td>\n",
       "      <td>83.1</td>\n",
       "      <td>1.08%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank          Language Speakers % of World pop.\n",
       "0    1  Mandarin Chinese      918          11.92%\n",
       "1    2           Spanish      480           5.99%\n",
       "2    3           English      379           4.92%\n",
       "3    4         Hindustan      341           4.43%\n",
       "4    5           Bengali      228           2.96%\n",
       "5    6        Portuguese      221           2.87%\n",
       "6    7           Russian      154           2.00%\n",
       "7    8          Japanese      128           1.66%\n",
       "8    9     Western Punja     92.7           1.20%\n",
       "9   10           Marathi     83.1           1.08%"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages['% of World pop.']=languages['% of World pop.'].astype(float)\n",
    "languages['% of World pop.'] = languages['% of World pop.'].apply(lambda x: \"{0:.2f}%\".format(x * 1))\n",
    "languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display IMDB's top 250 data (movie name, initial release, director name and stars) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "movie=soup.find_all(\"td\", class_=\"titleColumn\")\n",
    "movie_name=[re.findall('>.*</a',str(i)) for i in movie]\n",
    "initial_release=[re.findall('>.*</span',str(i)) for i in movie]\n",
    "director=[re.findall('title=.* \\(dir.', str(i)) for i in movie]\n",
    "rating=soup.find_all(\"td\",class_=\"ratingColumn imdbRating\")\n",
    "rating=[re.findall('>.*<',str(x)) for x in rating]\n",
    "IMDB=pd.DataFrame(data={'Movie Name':movie_name,'Initial Release':initial_release,'Director Name':director,'Stars':rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Initial Release</th>\n",
       "      <th>Director Name</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cadena perpetua</td>\n",
       "      <td>1994</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El padrino</td>\n",
       "      <td>1972</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El padrino: Parte II</td>\n",
       "      <td>1974</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El caballero oscuro</td>\n",
       "      <td>2008</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 hombres sin piedad</td>\n",
       "      <td>1957</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La lista de Schindler</td>\n",
       "      <td>1993</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>El señor de los anillos: El retorno del rey</td>\n",
       "      <td>2003</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>1994</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>El bueno, el feo y el malo</td>\n",
       "      <td>1966</td>\n",
       "      <td>Sergio Leone</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>El señor de los anillos: La comunidad del anillo</td>\n",
       "      <td>2001</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>El club de la lucha</td>\n",
       "      <td>1999</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>1994</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Origen</td>\n",
       "      <td>2010</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>El señor de los anillos: Las dos torres</td>\n",
       "      <td>2002</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>El imperio contraataca</td>\n",
       "      <td>1980</td>\n",
       "      <td>Irvin Kershner</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Matrix</td>\n",
       "      <td>1999</td>\n",
       "      <td>Lana Wachowski</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Uno de los nuestros</td>\n",
       "      <td>1990</td>\n",
       "      <td>Martin Scorsese</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Alguien voló sobre el nido del cuco</td>\n",
       "      <td>1975</td>\n",
       "      <td>Milos Forman</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Los siete samuráis</td>\n",
       "      <td>1954</td>\n",
       "      <td>Akira Kurosawa</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Seven</td>\n",
       "      <td>1995</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>La vida es bella</td>\n",
       "      <td>1997</td>\n",
       "      <td>Roberto Benigni</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ciudad de Dios</td>\n",
       "      <td>2002</td>\n",
       "      <td>Fernando Meirelles</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>El silencio de los corderos</td>\n",
       "      <td>1991</td>\n",
       "      <td>Jonathan Demme</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>¡Qué bello es vivir!</td>\n",
       "      <td>1946</td>\n",
       "      <td>Frank Capra</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>La guerra de las galaxias</td>\n",
       "      <td>1977</td>\n",
       "      <td>George Lucas</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Salvar al soldado Ryan</td>\n",
       "      <td>1998</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>El viaje de Chihiro</td>\n",
       "      <td>2001</td>\n",
       "      <td>Hayao Miyazaki</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>La milla verde</td>\n",
       "      <td>1999</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>2014</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parásitos</td>\n",
       "      <td>2019</td>\n",
       "      <td>Bong Joon Ho</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>La doncella</td>\n",
       "      <td>2016</td>\n",
       "      <td>Chan-wook Park</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Los cuatrocientos golpes</td>\n",
       "      <td>1959</td>\n",
       "      <td>François Truffaut</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>La pasión de Juana de Arco</td>\n",
       "      <td>1928</td>\n",
       "      <td>Carl Theodor Dreyer</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Andrei Rublev</td>\n",
       "      <td>1966</td>\n",
       "      <td>Andrei Tarkovsky</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Hotel Rwanda</td>\n",
       "      <td>2004</td>\n",
       "      <td>Terry George</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Spotlight</td>\n",
       "      <td>2015</td>\n",
       "      <td>Tom McCarthy</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Amores perros</td>\n",
       "      <td>2000</td>\n",
       "      <td>Alejandro G. Iñárritu</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>El odio</td>\n",
       "      <td>1995</td>\n",
       "      <td>Mathieu Kassovitz</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Rififi</td>\n",
       "      <td>1955</td>\n",
       "      <td>Jules Dassin</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Nausicaä del Valle del Viento</td>\n",
       "      <td>1984</td>\n",
       "      <td>Hayao Miyazaki</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>1976</td>\n",
       "      <td>John G. Avildsen</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Gangs of Wasseypur</td>\n",
       "      <td>2012</td>\n",
       "      <td>Anurag Kashyap</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Monstruos, S.A.</td>\n",
       "      <td>2001</td>\n",
       "      <td>Pete Docter</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Rebeca</td>\n",
       "      <td>1940</td>\n",
       "      <td>Alfred Hitchcock</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>2006</td>\n",
       "      <td>Rakeysh Omprakash Mehra</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Antes del atardecer</td>\n",
       "      <td>2004</td>\n",
       "      <td>Richard Linklater</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Retrato de una mujer en llamas</td>\n",
       "      <td>2019</td>\n",
       "      <td>Céline Sciamma</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Deseando amar</td>\n",
       "      <td>2000</td>\n",
       "      <td>Kar-Wai Wong</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>París, Texas</td>\n",
       "      <td>1984</td>\n",
       "      <td>Wim Wenders</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Sucedió una noche</td>\n",
       "      <td>1934</td>\n",
       "      <td>Frank Capra</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>2015</td>\n",
       "      <td>Nishikant Kamat</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Contratiempo</td>\n",
       "      <td>2016</td>\n",
       "      <td>Oriol Paulo</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>La princesa prometida</td>\n",
       "      <td>1987</td>\n",
       "      <td>Rob Reiner</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Criadas y señoras</td>\n",
       "      <td>2011</td>\n",
       "      <td>Tate Taylor</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>El circo</td>\n",
       "      <td>1928</td>\n",
       "      <td>Charles Chaplin</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>La batalla de Argel</td>\n",
       "      <td>1966</td>\n",
       "      <td>Gillo Pontecorvo</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Terminator</td>\n",
       "      <td>1984</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Aladdín</td>\n",
       "      <td>1992</td>\n",
       "      <td>Ron Clements</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>A Silent Voice</td>\n",
       "      <td>2016</td>\n",
       "      <td>Naoko Yamada</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Winter Sleep (Sueño de invierno)</td>\n",
       "      <td>2014</td>\n",
       "      <td>Nuri Bilge Ceylan</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Movie Name Initial Release  \\\n",
       "0                                     Cadena perpetua            1994   \n",
       "1                                          El padrino            1972   \n",
       "2                                El padrino: Parte II            1974   \n",
       "3                                 El caballero oscuro            2008   \n",
       "4                               12 hombres sin piedad            1957   \n",
       "5                               La lista de Schindler            1993   \n",
       "6         El señor de los anillos: El retorno del rey            2003   \n",
       "7                                        Pulp Fiction            1994   \n",
       "8                          El bueno, el feo y el malo            1966   \n",
       "9    El señor de los anillos: La comunidad del anillo            2001   \n",
       "10                                El club de la lucha            1999   \n",
       "11                                       Forrest Gump            1994   \n",
       "12                                             Origen            2010   \n",
       "13            El señor de los anillos: Las dos torres            2002   \n",
       "14                             El imperio contraataca            1980   \n",
       "15                                             Matrix            1999   \n",
       "16                                Uno de los nuestros            1990   \n",
       "17                Alguien voló sobre el nido del cuco            1975   \n",
       "18                                 Los siete samuráis            1954   \n",
       "19                                              Seven            1995   \n",
       "20                                   La vida es bella            1997   \n",
       "21                                     Ciudad de Dios            2002   \n",
       "22                        El silencio de los corderos            1991   \n",
       "23                               ¡Qué bello es vivir!            1946   \n",
       "24                          La guerra de las galaxias            1977   \n",
       "25                             Salvar al soldado Ryan            1998   \n",
       "26                                El viaje de Chihiro            2001   \n",
       "27                                     La milla verde            1999   \n",
       "28                                       Interstellar            2014   \n",
       "29                                          Parásitos            2019   \n",
       "..                                                ...             ...   \n",
       "220                                       La doncella            2016   \n",
       "221                          Los cuatrocientos golpes            1959   \n",
       "222                        La pasión de Juana de Arco            1928   \n",
       "223                                     Andrei Rublev            1966   \n",
       "224                                      Hotel Rwanda            2004   \n",
       "225                                         Spotlight            2015   \n",
       "226                                     Amores perros            2000   \n",
       "227                                           El odio            1995   \n",
       "228                                            Rififi            1955   \n",
       "229                     Nausicaä del Valle del Viento            1984   \n",
       "230                                             Rocky            1976   \n",
       "231                                Gangs of Wasseypur            2012   \n",
       "232                                   Monstruos, S.A.            2001   \n",
       "233                                            Rebeca            1940   \n",
       "234                                   Rang De Basanti            2006   \n",
       "235                               Antes del atardecer            2004   \n",
       "236                    Retrato de una mujer en llamas            2019   \n",
       "237                                     Deseando amar            2000   \n",
       "238                                      París, Texas            1984   \n",
       "239                                 Sucedió una noche            1934   \n",
       "240                                          Drishyam            2015   \n",
       "241                                      Contratiempo            2016   \n",
       "242                             La princesa prometida            1987   \n",
       "243                                 Criadas y señoras            2011   \n",
       "244                                          El circo            1928   \n",
       "245                               La batalla de Argel            1966   \n",
       "246                                        Terminator            1984   \n",
       "247                                           Aladdín            1992   \n",
       "248                                    A Silent Voice            2016   \n",
       "249                  Winter Sleep (Sueño de invierno)            2014   \n",
       "\n",
       "                Director Name Stars  \n",
       "0             Frank Darabont    9.2  \n",
       "1       Francis Ford Coppola    9.1  \n",
       "2       Francis Ford Coppola    9.0  \n",
       "3          Christopher Nolan    9.0  \n",
       "4               Sidney Lumet    8.9  \n",
       "5           Steven Spielberg    8.9  \n",
       "6              Peter Jackson    8.9  \n",
       "7          Quentin Tarantino    8.8  \n",
       "8               Sergio Leone    8.8  \n",
       "9              Peter Jackson    8.8  \n",
       "10             David Fincher    8.8  \n",
       "11           Robert Zemeckis    8.8  \n",
       "12         Christopher Nolan    8.7  \n",
       "13             Peter Jackson    8.7  \n",
       "14            Irvin Kershner    8.7  \n",
       "15            Lana Wachowski    8.6  \n",
       "16           Martin Scorsese    8.6  \n",
       "17              Milos Forman    8.6  \n",
       "18            Akira Kurosawa    8.6  \n",
       "19             David Fincher    8.6  \n",
       "20           Roberto Benigni    8.6  \n",
       "21        Fernando Meirelles    8.6  \n",
       "22            Jonathan Demme    8.6  \n",
       "23               Frank Capra    8.6  \n",
       "24              George Lucas    8.6  \n",
       "25          Steven Spielberg    8.5  \n",
       "26            Hayao Miyazaki    8.5  \n",
       "27            Frank Darabont    8.5  \n",
       "28         Christopher Nolan    8.5  \n",
       "29              Bong Joon Ho    8.5  \n",
       "..                        ...   ...  \n",
       "220           Chan-wook Park    8.0  \n",
       "221        François Truffaut    8.0  \n",
       "222      Carl Theodor Dreyer    8.0  \n",
       "223         Andrei Tarkovsky    8.0  \n",
       "224             Terry George    8.0  \n",
       "225             Tom McCarthy    8.0  \n",
       "226    Alejandro G. Iñárritu    8.0  \n",
       "227        Mathieu Kassovitz    8.0  \n",
       "228             Jules Dassin    8.0  \n",
       "229           Hayao Miyazaki    8.0  \n",
       "230         John G. Avildsen    8.0  \n",
       "231           Anurag Kashyap    8.0  \n",
       "232              Pete Docter    8.0  \n",
       "233         Alfred Hitchcock    8.0  \n",
       "234  Rakeysh Omprakash Mehra    8.0  \n",
       "235        Richard Linklater    8.0  \n",
       "236           Céline Sciamma    8.0  \n",
       "237             Kar-Wai Wong    8.0  \n",
       "238              Wim Wenders    8.0  \n",
       "239              Frank Capra    8.0  \n",
       "240          Nishikant Kamat    8.0  \n",
       "241              Oriol Paulo    8.0  \n",
       "242               Rob Reiner    8.0  \n",
       "243              Tate Taylor    8.0  \n",
       "244          Charles Chaplin    8.0  \n",
       "245         Gillo Pontecorvo    8.0  \n",
       "246            James Cameron    8.0  \n",
       "247             Ron Clements    8.0  \n",
       "248             Naoko Yamada    8.0  \n",
       "249        Nuri Bilge Ceylan    8.0  \n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB['Movie Name']=IMDB['Movie Name'].apply(lambda x: re.sub('</a','',str(x)))\n",
    "IMDB['Movie Name']=IMDB['Movie Name'].apply(lambda x: x[3:-2])\n",
    "IMDB['Initial Release']=IMDB['Initial Release'].apply(lambda x: re.sub('</span','',str(x)))\n",
    "IMDB['Initial Release']=IMDB['Initial Release'].apply(lambda x: x[4:-3])\n",
    "IMDB['Director Name']=IMDB['Director Name'].apply(lambda x: re.sub('title=','',str(x)))\n",
    "IMDB['Director Name']=IMDB['Director Name'].apply(lambda x: x[3:-7])\n",
    "IMDB['Stars']=IMDB['Stars'].apply(lambda x: re.sub('>','',str(x)))\n",
    "IMDB['Stars']=IMDB['Stars'].apply(lambda x: x[2:-3])\n",
    "IMDB.replace(['>', '<'],inplace=True )\n",
    "IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = input('Enter the city: ')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the book name, price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
